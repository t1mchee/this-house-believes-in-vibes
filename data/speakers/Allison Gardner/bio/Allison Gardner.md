# About me

 I previously worked with the NHS as a Senior Scientific Adviser for Artificial Intelligence. I also served as a director of 'Women Leading in AI' and worked internationally with governments and organizations such as the UN to advocate for the ethical use of Artificial Intelligence.

Before this, I spent over 25 years as a Science and PSHE teacher in secondary schools. During that time, I completed a PhD in Molecular Biology (for fun!) and later lectured at Keele University, where I led the Data Science Degree Apprenticeship programme.

  

I spent six years as a councillor in Newcastle-under-Lyme, where I also served as Chair of the CLP. I was the campaign coordinator for the 2017 general election, achieving a remarkable victory against all odds. Additionally, I was one of the leading campaigners to save Bradwell Community Hospital and have earned respect across North Staffordshire for my passionate commitment to the area.

  

As a 'military baby,' I was born in Singapore, where my Navy father was stationed, but I was raised by my Irish mother, who worked as a factory manager. I credit my mum, who began her working life as a cleaner, for instilling in me a strong work ethic, resilience, and determination to succeed.
**Core Themes Relevant to the Motion**

- **Algorithmic bias and fairness**, especially in health, social care, and policing.
    
- **Governance and regulation of AI**, focusing on algorithmic impact assessments, audits, and standards.
    
- Gender, diversity and representation in AI development as a condition for **trustworthy AI**.
    

**Profiles & Overviews**

1. **JUMP Forum Speaker Bio** – summarises her work on gender, AI ethics, governance, and machine learning in health.
    
    - [http://jump.eu.com/jup/forum-speakers/allison-gardner/](http://jump.eu.com/jup/forum-speakers/allison-gardner/)[](http://jump.eu.com/jup/forum-speakers/allison-gardner/)​
        
2. **ForHumanity Fellow Profile** – details her roles in AI ethics, algorithmic bias, IEEE P7000/P7003 standards, and algorithmic impact assessments.
    
    - [https://forhumanity.center/fellow/allison-gardner/](https://forhumanity.center/fellow/allison-gardner/)[](https://forhumanity.center/fellow/allison-gardner/)​
        
3. **Women Leading in AI – About Us** – outlines the network she co‑founded, with aims around equality, policy, and fairness in AI.
    
    - [https://womenleadinginai.org/about](https://womenleadinginai.org/about)[](https://womenleadinginai.org/about)​
        
4. **LinkedIn (as MP for Stoke‑on‑Trent South, AI & Data Ethics expert)** – confirms her political role and ongoing AI ethics focus.
    
    - [https://www.linkedin.com/in/dr-allison-gardner](https://www.linkedin.com/in/dr-allison-gardner)[](https://www.linkedin.com/in/dr-allison-gardner)​
        

**Talks, Podcasts & Slides on Bias and Governance**

5. **“Diversity and Gender Bias in Artificial Intelligence” (JUMP Forum Brussels talk)** – video focusing on biased training data, high error rates on darker‑skinned women, and lack of diversity in AI teams; argues for regulation, audits, and impact assessments.​[](http://jump.eu.com/wp-content/uploads/2019/04/2019_JUMP_Forum_Brussels_AGardner_DiversityBiasinAI.pdf)​
    
    - Video: [https://www.youtube.com/watch?v=q_HSD5n8RFY](https://www.youtube.com/watch?v=q_HSD5n8RFY)​
        
    - Slide deck (PDF): [http://jump.eu.com/wp-content/uploads/2019/04/2019_JUMP_Forum_Brussels_AGardner_DiversityBiasinAI.pdf](http://jump.eu.com/wp-content/uploads/2019/04/2019_JUMP_Forum_Brussels_AGardner_DiversityBiasinAI.pdf)[](http://jump.eu.com/wp-content/uploads/2019/04/2019_JUMP_Forum_Brussels_AGardner_DiversityBiasinAI.pdf)​
        
6. **Podcast: “Small nudges towards more responsible AI” (Response‑Ability)** – discussion of responsible AI in health, roles of investors and clinicians, and why deskilling and lack of oversight pose dangers.
    
    - Episode + transcript: [https://response-ability.tech/03-small-nudges-towards-responsible-ai-with-allison-gardner/](https://response-ability.tech/03-small-nudges-towards-responsible-ai-with-allison-gardner/)[](https://response-ability.tech/03-small-nudges-towards-responsible-ai-with-allison-gardner/)​
        
7. **Article: “Don’t write off algorithms – responsible AI can produce real benefits” (The Conversation, hosted at Keele)** – argues that algorithms can help in low‑risk, high‑impact uses when transparently trialled and scrutinised, but warns about design failures and legal challenges when used in high‑stakes domains without proper oversight.[](https://www.keele.ac.uk/about/news/2020/september/write-off-algorithms/ai-benefits.php)​
    
    - [https://www.keele.ac.uk/about/news/2020/september/write-off-algorithms/ai-benefits.php](https://www.keele.ac.uk/about/news/2020/september/write-off-algorithms/ai-benefits.php)[](https://www.keele.ac.uk/about/news/2020/september/write-off-algorithms/ai-benefits.php)​
        
8. **Chatham House podcast: “Undercurrents Summer Special: Allison Gardner on Artificial Intelligence”** – focuses on preventing bias in AI and how policymakers and businesses should collaborate.
    
    - [https://www.chathamhouse.org/2019/08/undercurrents-summer-special-allison-gardner-artificial-intelligence](https://www.chathamhouse.org/2019/08/undercurrents-summer-special-allison-gardner-artificial-intelligence)[](https://www.chathamhouse.org/2019/08/undercurrents-summer-special-allison-gardner-artificial-intelligence)​
        
9. **Intelligent Health Ambassador profile** – emphasises her expertise in AI and Data Ethics, health technology, algorithmic bias, and diversity.
    
    - [https://london.intelligenthealth.ai/ambassadors/](https://london.intelligenthealth.ai/ambassadors/)[](https://london.intelligenthealth.ai/ambassadors/)​
        

These sources support positioning Gardner as arguing that **biased, opaque AI in high‑stakes settings (health, policing, welfare)** risks entrenching systemic injustice; she tends to advocate for **tight governance, audits, and algorithmic impact assessments**, and is sceptical of handing final life‑and‑death decisions to AI.

#### My Values

**Championing equality and fairness:**   

I believe we should all be treated with dignity and respect, that diversity is to be celebrated and we are all valued.

  

**Fighting for social justice:**  

I believe in standing up for the most vulnerable and tackling poverty and injustice wherever we find it.

  

**Empowering communities and engaging people:** 

I believe in thriving communities with the resources to work together to achieve a better quality of life for all.

  

**Defending and growing our public services:**

I believe in high quality, accessible services to meet the needs of our communities and our people at their heart.

**Hope for all our futures:**

I believe in the politics of hope that enables people to transform their lives and our environment for a fairer, greener and happier future.

Dr Allison Gardner is a Teaching Fellow at Keele University lecturing in Bioinformatics. Her research focuses on utilization of machine learning to predict disease, gender and computing, AI ethics and governance.

She works on the IEEE P7000 Global Initiative on the Ethics of Autonomous and Intelligent Systems and specifically P7003 on algorithmic bias, providing a framework for Algorithmic Impact Assessments. Allison speaks nationally on AI Ethics, machine bias and the need for diversity and regulation in the field of AI.

She is a co-founder of Women Leading in AI, encouraging women to shape the debate around the use and norms of AI and big data. She is an experienced Chair and has acted as a consultant for a variety of companies advising on AI ethics.

Allison is a local councillor, chairs the Conservation Advisory Working Party, sits on the Economic Development and the Health scrutiny committees and is a school governor. She is an alumnus of the first cohort of the Jo Cox Women in Leadership Programme.