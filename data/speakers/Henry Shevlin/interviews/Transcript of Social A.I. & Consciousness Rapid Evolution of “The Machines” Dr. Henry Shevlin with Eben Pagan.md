today I'm speaking with Dr Henry chevlin a philosopher and AI ethicist Dr chevlin is the associate director and program director at the lever Hume center for the future of intelligence as a senior research associate he's also published numerous influential papers on AI ethics Consciousness cognitive science and more he's now a global voice that is Examining The Deep ethical implications of artificial intelligence so welcome Dr chevin it's really great to have you here wonderful great to be here eban and please uh call me Henry that's great so you're a philosopher you're an AI uh ethicist okay so I mean not to get into you know make this a college class or anything but what is philosophy what is AI what is ethics why did you find yourself uh you know at the intersection of these amazing things yeah so what if what is philosophy is a gigantic question I've uh even do um a lecture for our new master students on the a AI Ethics program uh a 90-minute lecture what is philosophy uh but to just kind of give you the cliff notes version um I would say that philosophy is a really a set of methods as much as a single cohesive discipline a wide variety of topics obviously get studied by philosophers everything from the nature of beauty to the nature of time to the nature of ideal governments and political systems but my specific area of philosophy is what's sometimes called philosophy of cognitive science so working very closely uh with the results coming out of different uh um empirical disciplines different areas of science like Neuroscience psychology uh Behavior computer science and trying to do some theoretical work to make sense of those results so to give an example of a a question that I think a lot of people have been asking recently that is fall squarely within my wheel house if you want to address a question like uh does chat GPT understand can it engage in reasoning so these are the kind of classic questions about uh that fall within philosophy of cognitive science and what about Ai and ethics and I I mean I'm you know looking for the cliff notes on all these and what what is the intersection of these three things so AI ethics is an emerging field um an emerging interdisciplinary field that draws on everyone from LA lawers to sociologists to philosophers and it's basically I think in in a nutshell about trying to get AI right trying to ensure that AI tools are conducive to human thriving and don't cause unexpected catastrophes or contribute to political or social problems we already have but it's a very broad church with people from a whole range of disciplines as I say at CFI uh the lead center for the future of intelligence um where I'm based at Cambridge um we have a huge team of um 40 researchers uh from at least a dozen probably more different disciplines and we're all kind of United under this Banner of AI ethics yeah uh what's the most interesting thing happening right now with uh with AI in your opinion we were just talking right before we you know switched on what are the most interesting develop developments you're seeing right now so if if I can answer first with a meta level reflection which is this is AI the field of AI as a whole is in a utterly bizarre and historically very unusual period of progress right now I think just to give a little example we started our first AI ethics Masters program back in 2021 and when we welcomed our students to that course um very few of them had even used any kind of AI tools Because unless you're working at Amazon or Microsoft or Google back in 2021 um you weren't directly using uh there was no equivalent to chat GPT or stable diffusion or mid Journey um of course people interacted with AI maybe without realizing it in simple things like content recommendation algorithms or the kind of products that Amazon was linking them but they didn't use AI themselves they they weren't like at the controls driving the machine they didn't know they didn't get a sense of the power yeah exactly yeah and then of course by the end of when that cohort finished it was the the end of 2023 in chat GPT had launched and suddenly hundreds of millions of people were using AI on a daily basis and um the speed at which new products have emerged since then new generations of models whole new applications of AI this is just not a normal condition for any technology to be in uh I've compared it to being at the heart of the Industrial Revolution but um the Industrial Revolution if you look it historically it it play out over several decades and was quite slow in its early stages even thinking back to some to Revolution another Revolution that I I've lived through uh the internet you know it took um quite a long time you know from the uh from the 80s as a arpanet um slowly diffusing out across uh across different uh user bases and it wasn't really until sort of the mid late 90s that a lot of people uh it became very normal for people to go online so that was a relatively slow Revolution although again quite fast by historical standards what's happening now with AI is just completely historically unprecedented yeah yeah yeah yeah yeah my my personal metaphor is camarine explosion I uh remember reading a really interesting story by a uh well some research by a scientist who his theory was that uh it was vision and sight that trer triggered the camarine explosion because all of a sudden you could see your prey and you could see your mates and then there's like this all these New Dimensions and so it is it's it's as if there's all these new forms of intelligence that are like sprouting and you know turning into uh these meta entities I don't even know what they are in fact I'm actually interested to understand when you think of AI or generative AI how do you hold it in your mind what do you think of it as yeah so I think having these kind of Frameworks is very important and the most basic cut across different AI systems to try and carve up that space is on the one hand the kind of AI system we're familiar with through chat GPT uh I you could think of this as the kind of humanlike AI um typically using Transformer architectures and this is the kind of AI you can have a conversation with the classic AI assistant um and in one uh one recent paper I've talked about this is anthropo mic AI which is a very fancy word but basically meaning humanlike deliberately trying to be human likee and then sort of the other main category I think in this just this first past categorization would be the kind of systems that uh Deep Mind Deep Mind for example in London are building um that use uh mainly deep reinforcement learning and you know you can't have a conversation with them you you put up an API if you want to do protein folding or uh search for C different kinds of Crystal structures one of that was a model they built last year um and there are a whole bunch of tools like that uh that you know you can't talk to but have powerful abilities to um for design or Material Science and so forth and um I think these are two very different pillars and neither of them are going to go away uh I think we'll see these two different types of system developing in parallel for different use cases so in the case of um anthropo mimic AI the humanlike ones like chat GPT there are just so many use cases that we're beginning to explore now where that is very much a core feature that you can talk to the model I'm thinking of areas like education where you want a tutor who can interact with you one-on-one personal um uh a lot of healthcare contexts like first past diagnostic medicine um or more generally if you're building tools that you want a not particularly Tech savy employee or person in your organization to use so the kind of tools that are being developed uh in law firms for example um for paralal work using AI so that is a whole cluster of AI applications AI use cases um and the other cluster is also not going away of course we're still seeing amazing new models being built um to for these much more specialized purposes um like U protein folding or yeah synthetic biology and so forth do you think of them as entities I mean do you think of them as conscious like when you in your private mind when you're sitting down with chat GPT how are you relating to it are you think of it as a computer or database or like what are you how are you holding it I think it's basically impossible to interact with chat GPT without at least slipping into the fiction that you are dealing with a mind it's uh we have to adopt what the philosopher Daniel dennet has called the intentional stance um you can sort of force yourself to realize that you know at some level you're dealing with uh matrix multiplication or next token prediction but it's very hard to keep that at the Forefront of your imagination I think um one interesting observation about humans as a species is that we are relent anthropomorphizes we routinely attribute mental states to things that don't really have them um you know one one fun example uh I'm a I have a real problem with hoarding uh and I find it really hard to Chuck stuff away and I'm a big fan of Marie condo um and you know one little tip she gives is if you're struggling to get rid of something you can just say thank you for your service and that makes it a little bit easier to throw it away so I use that tip all the time and that's OB a form of anthropomorphism but I think there's a distinction I would draw between what I would call ironic anthropomorphism where you kind of know that it's it's not real you're not really committing to the idea that the thing you're attributing mental states to whether it's your car or some item you're throwing away or characters in a video game you know they don't really have Minds it's but it's just a nice willing suspension disbelief and I'd contrast that with unironic anthropomorphism which is where you sincerely reflectively endorse the idea that the system you're interacting with does have mental States and I think a landmark event here a real wakeup call for a whole whole bunch of people working in philosophy in cognitive science in AI was uh the Blake CL moin incident so this was uh summer of 2022 I'm sure you you're familiar uh a Google employee named Blake Le Moine went public with claims that the Lambda model which was the predecessor of the Gemini model um he said it was um he had been convinced through his interactions with it that it was conscious um and even I think started to see about trying to obtain it legal representation now I I don't think that's probably true that uh the model is conscious I think current AI systems are pretty poor Consciousness candidates but I think we also have to recognize that we are we're kind of fumbling in the dark a little bit here because we don't have anything like a consensus on the nature of Consciousness uh there are uh as many theories of Consciousness as there are Consciousness researchers uh I'm also a little bit pessimistic as someone who's done a lot of work in Consciousness science I'm a little bit pessimistic about the overall direction of the field I think it doesn't seem like we're making we're making progress on isolated questions here and there but it doesn't seem like we're converging on a single consensus Theory and um I think uh so I don't think we're going to get easy answers to these questions from Consciousness science anytime soon in the absence of getting definitive answers from the scientists I think it'll be interesting to see how much and in what ways people anthropomorphize AI uh the degree to which they really start to attribute the mental States uh start attributing the Consciousness and and so forth and I think it's uh it's going to be a really strange period of human society as we start to do this more and more and I think particularly as young people start to grow up interacting with AI buddies AI girlfriends AI boyfriends forming kind of new deep new uh new relationships with them deep relationships I think that is a generation that is probably going to go from the kind of unironic anamorphism that I think most of us do currently with chat GPT to something that looks a lot more like unironic ANM morphism really treating these things as though they they genuinely had mental States mhm so tell us what social AI is and you know what it what the field is and why you guys are interested in it and then maybe share that story you shared with me earlier yeah so social AI is basically the collective name for the variety of different AI companion apps that are out there these are May completely have missed uh the the attention of your listeners of your of your viewers um because they tend to be pretty Niche products probably the most famous one uh the one that gets the most press is something called replica with a k um which is an AI girlfriend AI boyfriend service but there are dozens of these things out there and um a lot of different Regional markets have their own version so for example in China there's uh something called Shia ice x i AO Ice uh which wasn't necessarily developed wasn't developed uh strictly as a social AI in the first first instance it was sort of a whole virtual personality but they've now added a chatbot component to that and according to one press release from the company and I I I couldn't believe these numbers when I saw them so I think there they might there might be some exaggeration going on but it is an official claim that's been made sh ice has 500 million users is what they claim even if it's just half of that that's still a huge user base I think rep replica is uh um has something somewhere around 16 million is the figure that I've seen quoted most recently so a lot smaller but um still a significant uh user base and um social AI uh is a very poorly uh very inadequately studied um phenomenon at the moment there are a lot of there are just a handful of papers of people who are seriously investigating um this phenomenon um but it is already having some pretty serious effects so we just saw today uh very sad news about um a boy a 14-year-old boy who's who was interacting with um an AI companion um he had I think he had made or using the character. a um service character to AI obviously one of the big social another another one of the big social AI uh providers um and uh a lawsuit is now being brought against character. a because this this boy very sadly committed suicide and it's been suggested it's been alleged that it was his interactions with the system that helped trigger this uh his decision to take his own life and there was another similar incident last year a Belgian man um a married father of two he got into a a really toxic sort of relationship with uh an AI companion using a service called chai GPT CH Ai and his widow said very clearly you know he uh if it hadn't been for his AI girlfriend and this toxic relationship they had uh he would still be here today so she attributed that firmly as the the fault of the AI um there's also a really spectacular incident uh Christmas day in 2021 a man showed up at the ground of winds a castle where the queen was staying uh with a crossbow uh and was arrested and basically said I'm here to kill here to murder the queen assassinate the queen and he was deep in uh deep in the throws of a whole bunch of delusions but he um uh he was subsequently tried and in the over the course of the trial it emerged that this plan was the product of his this bizarre relationship he had had with his social AI girlfriend um using the replica service and if you read the sentencing notes the judge is very clear like this played a major role in driving you to attempt this this bizarre this bizarre plot so there are some very serious effects that are happening uh from social AI um but I also just think we don't know how common they are or what the effect on the average user is uh so perhaps surprisingly the the sort of handful of papers that have been published looking at the impact of social AI on users um have found they tend to produce benefits at least users report benefits to their mental health to their relationships their relationships with other humans through using the apps and um although of course we now have two cases where two confirmed cases where social AI may have been involved in suicides there are there is also a study that quotes various users of people saying that this helped bring them from back from the brink of feeling suicidal so obviously it's kind of hard to balance kind of hard to know how many people social AI is helping versus how many it's harming and that's an area where I think we urgently need to be uh doing some more research I think there's uh the kind of quick elevator pitch for why I think this is so important uh is that social media has had so many consequences that were basically unanticipated whether it's misinformation political polarization privacy privacy breaches manipulation and so forth and I think we can't afford to make the same mistakes with social AI particularly if as was the case with social media young people are going to be at the Forefront of this all right so right now we're starting to see the rise in uh AI influencers right so what happens when we have ai influencers that are more attractive more intelligent more Charming than humans but then they're endorsing AI products or other products I mean this is your world a little bit right so what what's going to happen here yeah so I think this is another area where currently we don't have clear legal guidelines in place or clear ethical Frameworks to help us navigate this this new frontier so the simplest case I think is you're going to see this is uh in AI influencers as you say who might promote some kind of product but just thinking about sort of onetoone conversations that you might have with your social AI girlfriend boyfriend uh um AI buddy uh you know if you're a young person or for that matter an old person one of the things we like to talk about is products right we say oh I really am like the look of the new iPhone but I'm currently on Android so people are going to be having these conversations with AI systems and the answers to the questions that uh the AIS give are likely to be potentially quite impactful on people's purchasing uh but perhaps also more worryingly you might think even in their politics you know if someone asks their AI girlfriend what do you think of Joe Rogan or Jordan Peterson or what do you think about Israel and Palestine um there's going to be real I think potential impact there on people's beliefs and politics and uh I think it's it's potentially very powerful yeah source of um of Leverage of influence and I don't think we have clear ethical principles in place to help us navigate navigate that that con how much can an AI system weigh in on political questions how much can they endorse a a products do they should they be forced to reveal if they're getting any pay uh Kickbacks for example from companies to promote individual products so this is just like a taste of I think the ethical issues another related phenomenon uh we're also starting to see the rise of AI influencers or AI celebrities that are trained on the exact personalities of real celebrities so there was a service Karen AI um c r YN launched last year by an Instagram influencer so it was an AI trained up on all her social media utterances so it acted like it was her and users could pay a premium service to have sort of the girlfriend experience with this AI system so people are monetizing their own digital identities and I think that raises interesting questions about intellectual property uh should you require someone's consent to train a model on their public utterances for example again we just don't have a legal road map here to help us navigate okay quick action step here so the key is learning how to prompt better you start out prompting by just asking questions and talking to AI like it's a Helper but you quickly realize that getting better at prompting is a huge accelerator in GameChanger for your own success in life so these prompts will not only help you get a lot more done faster and accelerate your success but they'll also help you really get prompting and get better at it you can get all of these as a gift from me just by going to metamind . Co that's metam mind.co and I'll put that link below and then just opt in to get it I've also created a powerful video for you called AI in the future of business and work and success that demonstrates some of the key mindsets and prompting strategies to help you get up to speed and get a lot more out of generative Ai and it's also included as a free gift when you register so just head over to metam mind.co to get your AI accelerator prompt pack and the other free goodies all right back to our interview yeah so you know when I go to Google and I search something right it you know it started out there was nothing at the top it was just great quality search results and then all of a sudden there was paid promotions and then now it's like a whole page of you know paid Links at the top of Google and my experience is once in a while one of the paid links is the best search result but there's a fascinating like conundrum there right there's the Google is like they they built the Sy they built the system they built the algorithm they built the technology to get you the best quality results but then they made it so that you can buy your way to the top now if you take this to you know a a super intelligent digital mind and they're interacting with you real time you know I mean on on YouTube for example with one of my accounts I pay them the 10 bucks a month or whatever so that I don't see the ads but then when I'm over on my other account and I'm watching YouTube and I see the ads it's a completely different experience I mean it's totally different to see all these targeted ads to me but what happens when that's all invisible like do you pay do you pay 20 bucks a month so it doesn't sell you a whole bunch of stuff using super intelligence you know that you're you know and the one that you do pay 20 bucks a month for does it refer you to better higher quality things like how does this work I mean is it become your friend does it say I'm m at you I'm not going to talk to you unless you buy some of these products uh a lot of thorny issues here absolutely um so one of the most common questions I've asked when I go to companies and talk about large language models is um people want to know how you do SEO for uh chat GPT and currently and currently like there is no good way to ensure that if someone asks a model about your organization that you can have your talking points featured there I think that is something companies are going to navigate and probably find ways of monetizing allowing companies to for example provide the answers to certain queries or have influence on them but I think we're we're still not at that stage yet of that being a well worked out business model I think more broadly the phenomenon you're describing where Google search results have become perhaps less useful partly as a result of all the paid promoted content but also just as a result of the world's getting really good at SEO uh um I think things are going to get a a lot more chaotic uh mainly because I think we're going to see and over the next couple of years even we're going to see an increasing number of AI agents making content online so right now uh if you go on to Reddit uh for example which is is one of my favorite resources if I'm trying to if I'm trying to follow the news or um trying to do tax support or whatever you're still dealing mostly with ments um and of course you know we have had bots on Reddit and Twitter as a problem for a while but once these things get really sophisticated and are increasingly capable of taking actions in the world um capable of uh generating content posting it fluidly engaging in a in a more nuanced ways with different kinds of commentators I think the amount of AI generated content out there is just going to swamp human generated content you know there's this theory for sort of 2014 is I think called the dead internet theory that said that there are basically way more bots on the internet than we realize I think probably that was jumping the gun but I think the internet is is going to be headed for that we are going to be in a uh in a CA of AI generated content and probably we will need something like an AI PA an AI assistant to help us navigate that to for example uh give us ACC uh help curate our feeds for us help uh shift out the various kinds of fishing attacks or scams and so forth from that from that sea of content yeah and how do you do that when again it's a lot more intelligent a lot faster a lot more in control of uh of these systems so you mentioned that you get called in by companies to do kind of highle teaching them what AI is upskilling uh and so forth I just read not too long ago that I think it's 77% of people who are using AI at work are saying that it's reducing their productivity I don't know if you saw that one I just find that to be completely fascinating like how you would use this to reduce your productivity and the fact that most people are having that experience I mean I understand sure all of a sudden you sit down and there's infinite options you know there's like all of this this like uh this Deluge of potential value that you could be creating it's a little bit overwhelming um but uh so first of all what do you think about Ai and produ tivity and this idea that most people are thinking it's reducing their productivity and then what are companies you know calling you in for what are they asking you what's what's going on in that world so I I think I've seen in both my own life and in the lives of friends ways in which chat GPT can just massively amplify the amount that you can do I I think in my own case I feel it's dramatically increased my productivity everything um from the amount of time required to research and prep classes or um write articles or even just you know simple stuff like uh like improving my ability to produce uh to do fancy stuff on Google Sheets or Excel I in so many areas I think it's just been a massive um productivity gold mine for me but I also understand why a lot of people might be finding it a distraction or a nuisance uh I think one of the most common problems I run into is that people basically think that chat GPT should be should work straight out out the gate you know you should be able to ask it whatever want and get a perfect answer straight away and there's maybe not as much awareness as there could be or should be that there is a real skill curve to using any kind of generative AI Tool uh and the more time you spend interacting with the system the better your prompting will be and also the kinds of queries you decided to bring to an AI so for example uh Hallucination is something that people talk about a lot as a problem and you know I have colleagues who say oh I can't I can't use it the rates of hallucination are super high and I can say in my own case I almost never run into hallucinations these days and I think it's mainly because I uh don't ask the kinds of questions where I know Hallucination is likely so the AI sort of trained me to to ask about the kind of areas just where and have a high where I'm pretty confident I'll get i'll get correct answers so I think that's one of the things that uh companies maybe are struggling with um is getting uh the upskilling in the use of these tools um for employees and I think a lot of people in company a lot of employees feel understandably oh great here's another tool that I have to learn how to use and I think the one of the best piece of advice I could give anyone is find a nonprofessional use case for generative AI so in my own case I'm a I I run a D and D campaign with for a whole bunch of friends and a good 30 to 40% of the time I spend with chat GPT is just using it to produce images for my campaigns or using it to produce backstories of NPCs and so forth so just quick question then um how do you prompt so that it acts like it's on Aderall rather than LSD I guess is the real question we're asking how do you prompt in a way that makes it not hallucinate so there's a whole complex skill ass set here you know I know companies uh different organizations are now running whole dedicated classes on Crafting better prompts I think it's the kind of thing that you really just learn through experience I think custom instructions are very powerful and uh so this is a feature in chat GPT that again a surprising number of users I think are unaware of where you can basically append to all prompts a description of the kind of personality the kind of role you want it to adopt so I my custom my custom instructions are at this point you know a work a work in progress that I've been fiddling with and tweaking for uh going on yeah a year and a half now um so that's one of the tools fiddling with the custom instructions getting those right also I think something that took me a while to realize is very often it can be useful to ask chat GPT or Claude what information would be helpful for it to know before it gives you the answer to a question so for example if you're putting together a new diet plan don't just say I a diet plan or just give it a whole bunch of information and say give me a diet plan say okay here's some information about the kind of diet plan I'm looking for what would it be helpful for you to know before you come up with a proper diet plan for me so I by the way I agree with you using generative AI across your whole life is how you you know kind of Bolt it on or use it as a yeah so what are some uh examples of this so for me one of the most exciting ways I most enjoyable ways I use chat GPT is just whenever I'm on a long car journey by myself I just you know stick it on speaker phone and we'll have a good chitchat and talk talk to it for potentially two hours on the road whether it's me asking questions about Roman history or some or the his or the history of disco music or even doing fun stuff like getting it to give me quizzes or sometimes maybe more professionally if I'm going to a conference for example I might give a quick version of my presentation and see if it has any recommendations for feedback and I think this uh the voice The Voice functionality of chat GPT really is an important part of the user experience for me and I think it whilst a lot of people might think of it as just a gimmick it really really does change your experience and makes it available to I think users who would not otherwise perhaps interact with chat GPT so I think I think of my dad here he's 79 years old I remember back in November 2022 when I showed him chat GPT he's like oh that's cool I I probably am not going to use it but yeah seems cool and then about a uh nine months later when they' Unleashed uh they released just the first basic version of chat gpt's voice functionality I showed him that and he said this is going to change my life and I set him up with an account and he claims that he speaks to he's spoke in to chat GPT every day since then uh he's he calls it Allan after Alan touring and you know I think a lot of the time he he's when he's had a few beers he'll just sort of say hey hey Allan let's have a good debate and he'll pick a topic and they'll find something to to argue about um and of course I don't think he would be doing that in text format but voice really really is a game changer for it wow that's uh that's really beautiful all right doctor does this thing eventually wake up does it become sentient does it have self-awareness does it get agency and I mean kind of philosophically does it really matter if it does if it takes over and start self-improving and taking over all the resources and it's not actually self-aware but it's on the way to but it looks to us like it is does that even matter what do you think philosopher yeah well so I think the first thing to flag here is that cognitive science does not have any consensus definitions for pretty much any of the major mental state psychological Concepts whether we're talking about sentience whether we're talking about reasoning whether we're talking about creativity these are all massively contest ideas so people confidently weighing in saying oh chat GPT really doesn't do reasoning um and you know giving a whole Theory as to why well it it really depends on what we mean by reasoning and as I said there's no consensus definitions there so that I think is one thing to bear in mind when asking these questions about you know about selfawareness and so forth uh I also think it's important to separate out the questions about AI safety and recursive self-improvement movement Singularity type issues from Consciousness uh I don't think there's any reason to assume that only only conscious AI would be threatening in the ways that people sometimes think of uh super intelligence as potentially threatening uh in fact I generally think that Consciousness is a bit of a red herring in that whole debate it doesn't matter if the AI is conscious if it uh it's either dangerous or not um and if it is conscious that that does have some relevance for other questions which I'll come to come to in a second but yeah so I think separating off the singularity type worries from AI Consciousness worries is is quite important move in that debate so as to whether these systems will display well it's interesting you said self-awareness uh I think for some theories of self-awareness or some forms of self-awareness they already display this right so there was a really nice demonstration I saw of chat GPT passing version of the mirror test so you know the mirror test is a classic psychological experiment where you smear some paint on someone's on a on a child's face often like a little smear of red paint and they see themselves in the mirror and uh around I think 18 months two years human infants will reach up and wipe off the red paint and people have now applied mirror self- recognition tests to a whole bunch of different animal species and chat GPT kind of passes a version of this if you uh if you take a picture a photograph of your chat with chat GPT upload it and say what what are we looking at here uh at least some of the time it will correctly say oh that looks like the dialogue window in which we're having this very conversation so on at least some soft Notions of self-awareness I think these systems already have a kind of self-awareness um additionally these systems I think are surprisingly good at social cognition uh reasoning about uh people's motivations um and I think this is something it's easy to miss uh or easy to un under underestimate because a lot of people I think still operating with something like the commander data model of AI where AI is going to be really good at maths and reasoning and so forth but the kind of soft human emotional skills are going to be really challenging but there's no reason there's no real evidence that that's the case uh a whole bunch of work and claims and counter claims have been made about just how good current large language models are at Social reasoning but there are some really impressive results so for example a group of researchers um at Google uh Winnie Street and her team um looked at multi-level theory of Mind abilities in large language models and multi-level theory of mind is uh cases where you asked something like you're given a story a vignette and you asked something like does John believe that Brenda wants David to think that Allison doesn't like Ben um and a surprise humans are surprisingly good at this we can usually deal pretty well up to about sort of five levels five levels of sort of embedded theory of mind um but surprisingly GPT 4 40 is also really really good at these and even beats humans once you get to six levels of embedded uh theory of mind so um I think lots of forms of social awareness and self-awareness these systems already have it but I'm still sort of skirting around the big question which is you know could there ever be anything it's like could it to be an AI system could they ever have subjective experience um and here I'm pretty pessimistic about our ability to answer that question in any kind of scientific uh in in any kind of robust scientific fashion there are just so many basically metaphysical questions um metaphysical debates that are going to shift your answer so um one leading view in one major view about the nature of Consciousness is that it's fundamentally bound up with living systems so sort of iof fact to A system that wasn't alive couldn't be conscious that's if you called bioc psychism has many prominent recent Defenders um other people Defender view about Consciousness called illusionism which says that Consciousness doesn't really exist or we're just tricked into thinking we're conscious uh and there's just a whole variety of positions like that wildly different positions that make fundamentally different claims about uh the distribution of Consciousness in the world and what Consciousness is and they've been dueling it out for thousands at least hundreds of years at this point so I don't think we're going to resolve them in a way that tells us decisively if an AI system is conscious which AI systems are conscious instead I think that these debates are going to be largely resolved by the general public and Via our deepening interactions with AI systems so my prediction is that over the next 10 15 years human AI relationships whether those are more kind of Collegiate relationships or Intimate Relationships or friendships are just going to become so much more profound so much more Dynamic so much more sophisticated it will be almost impossible for us not to uh me mentalize to anthromorph AI systems maybe in this ironic sense at first but I think increasingly unironically so while the philosophers and scientists are still arguing about whether the AI systems are conscious I think a lot of people will just conclude implicitly that they are because of the kind of relationships they have with them thank you for your time today I've uh learned a lot it's been very insightful we'll put some uh links down below to to your work and thank you for coming Wonder great being here thanks so thank you for watching another metamind AI interview remember to keep practicing prompting keep learning get our prompt pack and quick start video watch our other videos to learn from other AI experts and stay tuned to us here on metamind stay subscribed because this is going to get really interesting