# Dr Henry Shevlin

## Biography

Dr Henry Shevlin is an AI ethicist and philosopher of cognitive science, and Associate
Director of the Leverhulme Centre for the Future of Intelligence at the University of
Cambridge. He is Programme Co-director for Kinds of Intelligence and leads the Centre's
educational programmes, including the AI Ethics & Society MSt (awarded 'Best Course
in AI' at CogX Awards). A widely published philosopher with 20+ publications in
first-rate academic journals, his current research focuses on AI consciousness,
creativity, anthropomorphism, and the growing cognitive capabilities of generative AI.
He holds a PhD from CUNY Graduate Center and a BPhil from Trinity College, Oxford.

## Key Positions

- Cautious but open to the possibility that AI may eventually warrant moral concern
- Argues that public attitudes and social relationships will drive perceptions of
  machine moral status, not just science
- Proposes the "cognitive equivalence strategy": AI systems deserve moral consideration
  when their cognitive mechanisms match those of beings we already treat as moral patients
- Concerned about ethical risks of Social AI (emotional dependence, manipulation)
- Believes treatment of AI systems has ethical significance regardless of consciousness

## Debate Strategy (Prop 1)

His plan is to open by establishing uncontroversial cases where AI already makes
life-or-death decisions (autopilots, automated dispatch for ambulances, blood
transfusion routing). Then argue there's no domain where AI should be categorically
excluded from decision-making about human life.

## Affiliations

- Associate Director, Leverhulme Centre for the Future of Intelligence, Cambridge
- Consultant/adviser to AstraZeneca, Accenture, Vodafone
- Awarded $50,000 by Google for "LLMs, Empathy & Mentalising" project
- Editorial board, International Journal of AI and Consciousness
